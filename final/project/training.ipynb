{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Install dependencies\n",
    "# # !pip3 uninstall numpy\n",
    "# !pip3 install --upgrade numpy==2.0.0\n",
    "# !pip3 install pandas\n",
    "# !pip3 install scikit-learn mlflow seaborn shap\n",
    "# !pip3 install bayesian-optimization\n",
    "# !pip3 install xgboost==2.1.2\n",
    "# !pip3 install optuna\n",
    "# !pip3 install optuna-integration[mlflow]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "from mlflow.models import infer_signature, make_metric\n",
    "from optuna.integration.mlflow import MLflowCallback\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import optuna\n",
    "import pickle, zipfile  \n",
    "import os, json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset\n",
    "Because test dataset not have label, we must split train dataset to 2 parts. One for train and one for validate. We just do this on the first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset\n",
    "# df = pd.read_csv('data/data.csv')\n",
    "# train_test_data, validate_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "# train_test_data.to_csv('data/train_.csv', index=False, header=True)\n",
    "# validate_data.to_csv('data/validate.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we check some information of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                      0\n",
       "flow_duration           0\n",
       "Header_Length      155801\n",
       "Protocol type      155810\n",
       "Duration           156043\n",
       "Rate               156180\n",
       "Srate              156075\n",
       "Drate              156049\n",
       "fin_flag_number         0\n",
       "syn_flag_number         0\n",
       "rst_flag_number    156030\n",
       "psh_flag_number    156006\n",
       "ack_flag_number         0\n",
       "ece_flag_number    155889\n",
       "cwr_flag_number    156119\n",
       "ack_count          156078\n",
       "syn_count          156278\n",
       "fin_count               0\n",
       "urg_count               0\n",
       "rst_count               0\n",
       "HTTP               155993\n",
       "HTTPS              156399\n",
       "DNS                     0\n",
       "Telnet             156044\n",
       "SMTP               155832\n",
       "SSH                156261\n",
       "IRC                     0\n",
       "TCP                156010\n",
       "UDP                     0\n",
       "DHCP                    0\n",
       "ARP                156189\n",
       "ICMP               155988\n",
       "IPv                     0\n",
       "LLC                     0\n",
       "Tot sum            155800\n",
       "Min                156138\n",
       "Max                155961\n",
       "AVG                     0\n",
       "Std                156058\n",
       "Tot size           155938\n",
       "IAT                156215\n",
       "Number                  0\n",
       "Magnitue                0\n",
       "Radius             155906\n",
       "Covariance         156232\n",
       "Variance           156106\n",
       "Weight                  0\n",
       "Label                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check dataset\n",
    "df = pd.read_csv('data/train_.csv')\n",
    "# df.head()\n",
    "# print(\"Dataset column\")\n",
    "# df.columns\n",
    "# print(\"Summary of dataset info\")\n",
    "# df.info()\n",
    "# print(\"view dimensions of dataset\")\n",
    "# df.shape\n",
    "\n",
    "# for col in df.columns:\n",
    "#   if df[col].dtype != 'object':  # Exclude non-numeric columns\n",
    "#     min_val = df[col].min()\n",
    "#     max_val = df[col].max()\n",
    "#     print(f\"Column: {col}\")\n",
    "#     print(f\"Minimum: {min_val}\")\n",
    "#     print(f\"Maximum: {max_val}\")\n",
    "#     print()\n",
    "\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see some cell have null value, we can not drop which rows have null cell because it to much. So we just fill all null value = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nulls_with_random(df):\n",
    "    def fill_column(col):\n",
    "        if col.isnull().any():  # Only process columns with NaN values\n",
    "            col_min = col.min()\n",
    "            col_max = col.max()\n",
    "            # Ensure min and max are valid for randomization\n",
    "            if np.isnan(col_min) or np.isnan(col_max):\n",
    "                return col  # Skip if column only contains NaNs\n",
    "            col = col.apply(lambda x: np.random.uniform(col_min, col_max) if pd.isnull(x) else x)\n",
    "        return col\n",
    "\n",
    "    return df.apply(fill_column, axis=0)\n",
    "\n",
    "# Fill NaN values with random values\n",
    "\n",
    "random_fill = fill_nulls_with_random(df)\n",
    "\n",
    "# data_n_null.isnull().sum()\n",
    "# data_n_null.head()\n",
    "# data_n_null.duplicated().sum()\n",
    "# data_n_null['Label'].unique().tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For tracking during training, we using MLflow. The software defined by container in mlflow folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set mlflow as tracking server\n",
    "ML_TRACKING_URL = \"http://localhost:5000\"\n",
    "mlflow.set_tracking_uri(ML_TRACKING_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model\n",
    "We train with some model with these steps\n",
    "- We training with small part of dataset (0.2 or 0.3): dataset_frac\n",
    "- We log artifacts, we see some column less contribute in  Feature Importance Score, so we delete it\n",
    "- We train with full dataset, verify droped column is correct and need modify or not\n",
    "- We use RandomizedSearchCV to search parameter\n",
    "- We save best parameter to mlflow. With mlflow.sklearn.autolog, model and its metrics was save to model registry. We just download it and use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tags = {\n",
    "#     \"dataset_frac\": 1.0,\n",
    "#     \"test_size\" : 0.2,\n",
    "#     \"droped_column\" : ['ID','IPv','DNS','IRC','DHCP','ARP','SMTP','cwr_flag_number','ece_flag_number','Telnet','Drate','psh_flag_number','rst_flag_number','LLC', 'TCP','SSH','HTTPS','ack_flag_number','Std','Tot size', 'ack_count'],\n",
    "#     \"author\": \"Son Nguyen\"\n",
    "# }\n",
    "\n",
    "# def dct_objective(trial):\n",
    "#     with mlflow.start_run(nested=True) as run:\n",
    "#         # params = {\n",
    "#         #     \"max_features\": trial.suggest_int(\"max_features\", 30, 100, step=2),\n",
    "#         #     \"criterion\": trial.suggest_categorical(\"criterion\", [\"gini\"]),\n",
    "#         #     \"max_depth\": trial.suggest_int(\"max_depth\", 1000, 1500, step=50),\n",
    "#         #     \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 18, 30, step=2),\n",
    "#         #     \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 10, 16, step = 1),\n",
    "#         #     \"random_state\" : 42\n",
    "#         # }\n",
    "#         params = {\n",
    "#             \"max_features\": trial.suggest_int(\"max_features\", 50, 70, step=1),\n",
    "#             \"criterion\": trial.suggest_categorical(\"criterion\", [\"entropy\"]),\n",
    "#             \"splitter\": trial.suggest_categorical(\"splitter\", [\"best\"]),\n",
    "#             \"max_depth\": trial.suggest_int(\"max_depth\", 1100, 1800, step=50),\n",
    "#             \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 17, 24, step=1),\n",
    "#             \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 10, 16, step=1),\n",
    "#             \"min_impurity_decrease\": trial.suggest_float(\"min_impurity_decrease\", 0.0, 0.001, step=0.0001),\n",
    "#             \"ccp_alpha\": trial.suggest_float(\"ccp_alpha\", 0.0, 0.001, step=0.0001),\n",
    "#             \"class_weight\": trial.suggest_categorical(\"class_weight\", [None, \"balanced\"]),\n",
    "#             \"max_leaf_nodes\": trial.suggest_int(\"max_leaf_nodes\", 150, 250, step=5),\n",
    "#             \"random_state\": 42\n",
    "#         }\n",
    "#         model = DecisionTreeClassifier(**params)\n",
    "\n",
    "#         mlflow.sklearn.autolog()\n",
    "#         model.fit(X_train, y_train)\n",
    "#         y_pred = model.predict(X_test)\n",
    "#         accuracy = accuracy_score(y_test, y_pred)\n",
    "#         f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "#         precision = precision_score(y_test, y_pred, average='weighted')\n",
    "#         recall = recall_score(y_test, y_pred, average='weighted')\n",
    "#         mlflow.log_metric(\"accuracy\", accuracy)\n",
    "#         mlflow.log_metric(\"f1_score\", f1)\n",
    "#         mlflow.log_metric(\"precision\", precision)\n",
    "#         mlflow.log_metric(\"recall\", recall)\n",
    "\n",
    "\n",
    "#         feature_scores = pd.Series(model.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "#         plt.figure(figsize=(20, 20))\n",
    "#         sns.barplot(x=feature_scores, y=feature_scores.index)\n",
    "#         plt.xlabel('Feature Importance Score')\n",
    "#         plt.ylabel('Features')\n",
    "#         plt.title(\"Visualizing Important Features\")\n",
    "#         feature_importance_plot = \"feature_importance.png\"\n",
    "#         plt.savefig(feature_importance_plot, bbox_inches='tight')\n",
    "#         mlflow.log_artifact(feature_importance_plot)\n",
    "#         os.remove(feature_importance_plot)\n",
    "\n",
    "        \n",
    "#         metrics_file = \"model_summary.json\"\n",
    "#         metrics = {\n",
    "#             \"parameter\" : {**params},\n",
    "#             \"metrics\" : {\n",
    "#                 \"f1\" : f1,\n",
    "#                 \"precision\" : precision,\n",
    "#                 \"accuracy\" : accuracy,\n",
    "#                 \"recall\" : recall\n",
    "#             },\n",
    "#             \"droped_column\" : [tags[\"droped_column\"]]\n",
    "            \n",
    "#         }\n",
    "        \n",
    "#         with open(metrics_file, \"w\") as f:\n",
    "#             json.dump(metrics, f, indent=4)\n",
    "\n",
    "#         mlflow.log_artifact(metrics_file)\n",
    "#         os.remove(metrics_file)\n",
    "\n",
    "#         trial.set_user_attr(\"run_id\", run.info.run_id)\n",
    "#     return f1\n",
    "\n",
    "\n",
    "# def dct_callback(study, frozen_trial):\n",
    "#     winner = study.user_attrs.get(\"winner\", None)\n",
    "#     if study.best_value and winner != study.best_value:\n",
    "#         study.set_user_attr(\"winner\", study.best_value)\n",
    "#         if winner:\n",
    "#             improvement_percent = (abs(winner - study.best_value) / study.best_value) * 100\n",
    "#             print(\n",
    "#                 f\"Trial {frozen_trial.number} achieved value: {frozen_trial.value} with \"\n",
    "#                 f\"{improvement_percent: .4f}% improvement\"\n",
    "#             )\n",
    "#         else:\n",
    "#             print(f\"Initial trial {frozen_trial.number} achieved value: {frozen_trial.value}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# data = random_fill.drop(columns=tags['droped_column'])\n",
    "# data_sample = data.sample(frac=tags['dataset_frac'])\n",
    "# X = data_sample.drop(columns=['Label'])\n",
    "# scaler = StandardScaler()\n",
    "# X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# y = data_sample['Label']\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = tags['test_size'], random_state = 42)\n",
    "\n",
    "\n",
    "# mlflow.set_experiment(\"decision_tree\")\n",
    "# optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "\n",
    "\n",
    "\n",
    "# with mlflow.start_run(nested=True) as run:\n",
    "\n",
    "#     # mlflow.xgboost.autolog() can not put auto log here\n",
    "#     study = optuna.create_study(direction='maximize')\n",
    "#     study.optimize(dct_objective, n_trials=100, timeout=14400, callbacks=[dct_callback], show_progress_bar=True)\n",
    "#     # study.optimize(dct_objective, n_trials=100, timeout=100, callbacks=[dct_callback], show_progress_bar=True)\n",
    "    \n",
    "#     best_trial = study.best_trial\n",
    "#     best_run_id = best_trial.user_attrs['run_id']\n",
    "#     # best_param = study.best_params\n",
    "#     best_value = study.best_value\n",
    "\n",
    "#     model_name = \"Decision Tree\"\n",
    "#     client = mlflow.tracking.MlflowClient()\n",
    "#     latest_ = client.get_latest_versions(model_name, stages=None)[0]\n",
    "\n",
    "\n",
    "#     if latest_:\n",
    "#         previous_f1_score = client.get_metric_history(latest_.run_id, \"f1_score\")[-1].value\n",
    "#         if previous_f1_score >= best_value:\n",
    "#             print(f\"Last model is better. Current values {best_value}, latest values {previous_f1_score}\")\n",
    "#         else:\n",
    "#             model_uri = f\"runs:/{best_run_id}/model\"\n",
    "#             best_model = mlflow.register_model(model_uri, model_name)\n",
    "#             best_param = client.get_run(best_run_id).data.params\n",
    "\n",
    "#             client.update_registered_model(\n",
    "#                 name=model_name,\n",
    "#                 description=\"Best moldel\",\n",
    "#             )\n",
    "\n",
    "#             for key, value in best_param.items():\n",
    "#                 client.set_model_version_tag(\n",
    "#                     name=model_name,\n",
    "#                     version=best_model.version,\n",
    "#                     key=key,\n",
    "#                     value=value\n",
    "#                 )\n",
    "\n",
    "#             client.set_model_version_tag(\n",
    "#                 name=model_name,\n",
    "#                 version=best_model.version,\n",
    "#                 key=\"values\",\n",
    "#                 value=best_value\n",
    "#             )\n",
    "\n",
    "#             for key, value in tags.items():\n",
    "#                 mlflow.set_tag(key,value)\n",
    "#             mlflow.set_tag(\"job\", \"Decision Tree using optuna to search parameter\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tags = {\n",
    "#     \"dataset_frac\": 1.0,\n",
    "#     \"test_size\" : 0.2,\n",
    "#     # \"droped_column\" : ['ID'],\n",
    "#     \"droped_column\" : ['ID','IPv', 'Telnet', 'SMTP', 'IRC', 'SSH', 'DHCP', 'ARP', 'DNS', 'Drate', 'ece_flag_number', 'cwr_flag_number', 'Duration', 'HTTP','HTTPS'],\n",
    "#     \"author\": \"Son Nguyen\"\n",
    "# }\n",
    "\n",
    "# def rdf_objective(trial):\n",
    "#     with mlflow.start_run(nested=True) as run:\n",
    "#         params = {\n",
    "#             \"n_estimators\": trial.suggest_int(\"n_estimators\", 500, 1500, step=50),\n",
    "#             \"max_features\": trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\"]),\n",
    "#             \"criterion\": trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\",\"entropy\"]),\n",
    "#             \"max_depth\": trial.suggest_int(\"max_depth\",50, 100, step=10),\n",
    "#             \"max_leaf_nodes\": trial.suggest_int(\"max_leaf_nodes\", 100, 500, step=50),\n",
    "#             \"min_samples_leaf\": trial.suggest_float(\"min_samples_leaf\", 0.01, 0.1, step=0.01),\n",
    "#             \"min_weight_fraction_leaf\": trial.suggest_float(\"min_weight_fraction_leaf\", 0.01, 0.05, step=0.005),\n",
    "#             \"min_impurity_decrease\": trial.suggest_float(\"min_impurity_decrease\", 0.01, 0.05, step=0.001),\n",
    "#             \"ccp_alpha\": trial.suggest_float(\"ccp_alpha\", 0.01, 0.05, step=0.001),\n",
    "#             \"max_samples\": trial.suggest_float(\"max_samples\", 0.5, 1.0, step=0.01),\n",
    "#             \"class_weight\": trial.suggest_categorical(\"class_weight\", [None, \"balanced\", None, None]),\n",
    "#             \"random_state\": 42,\n",
    "#         }\n",
    "#         # params = {\n",
    "#         #     \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200, step=10),\n",
    "#         #     \"max_features\": trial.suggest_categorical(\"max_features\", [None, \"sqrt\", \"log2\"]),\n",
    "#         #     \"criterion\": trial.suggest_categorical(\"criterion\", [\"log_loss\", \"gini\", \"entropy\"]),\n",
    "#         #     \"max_depth\": trial.suggest_int(\"max_depth\", 500, 2000, step=50),\n",
    "#         #     \"max_leaf_nodes\": trial.suggest_int(\"max_leaf_nodes\", 100, 2000, step=50),\n",
    "#         #     \"min_samples_leaf\": trial.suggest_float(\"min_samples_leaf\", 0.01, 1.0, step=0.01),\n",
    "#         #     \"min_weight_fraction_leaf\": trial.suggest_float(\"min_weight_fraction_leaf\", 0.01, 0.5, step=0.01),\n",
    "#         #     \"min_impurity_decrease\": trial.suggest_float(\"min_impurity_decrease\", 0.01, 1.0, step=0.01),\n",
    "#         #     \"ccp_alpha\": trial.suggest_float(\"ccp_alpha\", 0.01, 1.0, step=0.01),\n",
    "#         #     \"max_samples\" : None,\n",
    "#         #     \"random_state\": 42\n",
    "#         # }\n",
    "#         model = RandomForestClassifier(**params)\n",
    "\n",
    "#         mlflow.sklearn.autolog()\n",
    "#         model.fit(X_train, y_train)\n",
    "#         y_pred = model.predict(X_test)\n",
    "#         accuracy = accuracy_score(y_test, y_pred)\n",
    "#         f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "#         precision = precision_score(y_test, y_pred, average='weighted')\n",
    "#         recall = recall_score(y_test, y_pred, average='weighted')\n",
    "#         mlflow.log_metric(\"accuracy\", accuracy)\n",
    "#         mlflow.log_metric(\"f1_score\", f1)\n",
    "#         mlflow.log_metric(\"precision\", precision)\n",
    "#         mlflow.log_metric(\"recall\", recall)\n",
    "\n",
    "\n",
    "#         feature_scores = pd.Series(model.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "#         plt.figure(figsize=(20, 20))\n",
    "#         sns.barplot(x=feature_scores, y=feature_scores.index)\n",
    "#         plt.xlabel('Feature Importance Score')\n",
    "#         plt.ylabel('Features')\n",
    "#         plt.title(\"Visualizing Important Features\")\n",
    "#         feature_importance_plot = \"feature_importance.png\"\n",
    "#         plt.savefig(feature_importance_plot, bbox_inches='tight')\n",
    "#         mlflow.log_artifact(feature_importance_plot)\n",
    "#         os.remove(feature_importance_plot)\n",
    "\n",
    "        \n",
    "#         metrics_file = \"model_summary.json\"\n",
    "#         metrics = {\n",
    "#             \"parameter\" : {**params},\n",
    "#             \"metrics\" : {\n",
    "#                 \"f1\" : f1,\n",
    "#                 \"precision\" : precision,\n",
    "#                 \"accuracy\" : accuracy,\n",
    "#                 \"recall\" : recall\n",
    "#             },\n",
    "#             \"droped_column\" : [tags[\"droped_column\"]]\n",
    "            \n",
    "#         }\n",
    "        \n",
    "#         with open(metrics_file, \"w\") as f:\n",
    "#             json.dump(metrics, f, indent=4)\n",
    "\n",
    "#         mlflow.log_artifact(metrics_file)\n",
    "#         os.remove(metrics_file)\n",
    "\n",
    "#         trial.set_user_attr(\"run_id\", run.info.run_id)\n",
    "#     return f1\n",
    "\n",
    "\n",
    "# def rdf_callback(study, frozen_trial):\n",
    "#     winner = study.user_attrs.get(\"winner\", None)\n",
    "#     if study.best_value and winner != study.best_value:\n",
    "#         study.set_user_attr(\"winner\", study.best_value)\n",
    "#         if winner:\n",
    "#             improvement_percent = (abs(winner - study.best_value) / study.best_value) * 100\n",
    "#             print(\n",
    "#                 f\"Trial {frozen_trial.number} achieved value: {frozen_trial.value} with \"\n",
    "#                 f\"{improvement_percent: .4f}% improvement\"\n",
    "#             )\n",
    "#         else:\n",
    "#             print(f\"Initial trial {frozen_trial.number} achieved value: {frozen_trial.value}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# data = random_fill.drop(columns=tags['droped_column'])\n",
    "# data_sample = data.sample(frac=tags['dataset_frac'])\n",
    "# X = data_sample.drop(columns=['Label'])\n",
    "# scaler = StandardScaler()\n",
    "# X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# y = data_sample['Label']\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = tags['test_size'], random_state = 42)\n",
    "\n",
    "\n",
    "# mlflow.set_experiment(\"random-forest\")\n",
    "# optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "\n",
    "\n",
    "\n",
    "# with mlflow.start_run(nested=True) as run:\n",
    "\n",
    "#     # mlflow.xgboost.autolog() can not put auto log here\n",
    "#     study = optuna.create_study(direction='maximize')\n",
    "#     study.optimize(rdf_objective, n_trials=100, timeout=14400, callbacks=[rdf_callback], show_progress_bar=True)\n",
    "#     # study.optimize(dct_objective, n_trials=100, timeout=100, callbacks=[dct_callback], show_progress_bar=True)\n",
    "    \n",
    "#     best_trial = study.best_trial\n",
    "#     best_run_id = best_trial.user_attrs['run_id']\n",
    "#     # best_param = study.best_params\n",
    "#     best_value = study.best_value\n",
    "\n",
    "#     model_name = \"RandomForestClassifier\"\n",
    "#     client = mlflow.tracking.MlflowClient()\n",
    "#     latest_ = client.get_latest_versions(model_name, stages=None)[0]\n",
    "\n",
    "\n",
    "#     if latest_:\n",
    "#         previous_f1_score = client.get_metric_history(latest_.run_id, \"f1_score\")[-1].value\n",
    "#         if previous_f1_score >= best_value:\n",
    "#             print(f\"Last model is better. Current values {best_value}, latest values {previous_f1_score}\")\n",
    "#         else:\n",
    "#             model_uri = f\"runs:/{best_run_id}/model\"\n",
    "#             best_model = mlflow.register_model(model_uri, model_name)\n",
    "#             best_param = client.get_run(best_run_id).data.params\n",
    "\n",
    "#             client.update_registered_model(\n",
    "#                 name=model_name,\n",
    "#                 description=\"Best moldel\",\n",
    "#             )\n",
    "\n",
    "#             for key, value in best_param.items():\n",
    "#                 client.set_model_version_tag(\n",
    "#                     name=model_name,\n",
    "#                     version=best_model.version,\n",
    "#                     key=key,\n",
    "#                     value=value\n",
    "#                 )\n",
    "\n",
    "#             client.set_model_version_tag(\n",
    "#                 name=model_name,\n",
    "#                 version=best_model.version,\n",
    "#                 key=\"values\",\n",
    "#                 value=best_value\n",
    "#             )\n",
    "\n",
    "#             for key, value in tags.items():\n",
    "#                 mlflow.set_tag(key,value)\n",
    "#             mlflow.set_tag(\"job\", \"RandomForest Classifier using optuna to search parameter\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d99c1984af74f2097fbff0b48d0c64d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/11 19:33:13 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\project\\mlsec\\final\\project\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [19:33:13] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run bedecked-yak-857 at: http://localhost:5000/#/experiments/2/runs/4988594afc194670b68fcf0141fa32f7\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/2\n",
      "Initial trial 0 achieved value: 0.9282446289195605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/11 19:53:27 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\project\\mlsec\\final\\project\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [19:53:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run indecisive-perch-518 at: http://localhost:5000/#/experiments/2/runs/44ffa124f4be46f68c384ff6e1412b24\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/2\n",
      "Trial 1 achieved value: 0.9386589022283047 with  1.1095% improvement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/11 20:07:58 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\project\\mlsec\\final\\project\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [20:07:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run calm-vole-747 at: http://localhost:5000/#/experiments/2/runs/4f76fb2baf544e1f8d17c71d10b83172\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/11 20:19:18 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\project\\mlsec\\final\\project\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [20:19:18] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run illustrious-pug-390 at: http://localhost:5000/#/experiments/2/runs/58ff91c80e504c13abe8dd86a043ea4d\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/2\n",
      "Trial 3 achieved value: 0.938670057435602 with  0.0012% improvement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/11 20:27:53 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\project\\mlsec\\final\\project\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [20:27:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run tasteful-asp-18 at: http://localhost:5000/#/experiments/2/runs/94fec1b6482e45bb927ce930b09f8c90\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/11 20:50:30 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\project\\mlsec\\final\\project\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [20:50:30] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run caring-rook-95 at: http://localhost:5000/#/experiments/2/runs/6900f9e05bbe4e42a6c6eb5ca602d74d\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/11 21:02:28 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\project\\mlsec\\final\\project\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [21:02:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run mercurial-panda-312 at: http://localhost:5000/#/experiments/2/runs/9baf738b1c3d4a4890ea86e7c2b43c7c\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/2\n",
      "Trial 6 achieved value: 0.9386847659421427 with  0.0016% improvement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/11 21:11:11 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\project\\mlsec\\final\\project\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [21:11:11] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run rogue-donkey-387 at: http://localhost:5000/#/experiments/2/runs/556d9f51850f404d8cb97ca46e3c0191\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/11 21:21:56 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\project\\mlsec\\final\\project\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [21:21:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run luxuriant-mole-349 at: http://localhost:5000/#/experiments/2/runs/ab6a783b14564d9cb399313c323fb4f4\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/11 21:35:55 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\project\\mlsec\\final\\project\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [21:35:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run selective-fawn-766 at: http://localhost:5000/#/experiments/2/runs/2cd9c8c47b034b7a897aeca37dbc3bbd\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/2\n",
      "Trial 9 achieved value: 0.9391637958468314 with  0.0510% improvement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/11 21:54:00 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\project\\mlsec\\final\\project\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [21:54:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run overjoyed-koi-893 at: http://localhost:5000/#/experiments/2/runs/51d37263cc874bc8a08cc4069863b11b\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/2\n"
     ]
    }
   ],
   "source": [
    "tags = {\n",
    "    \"dataset_frac\": 1.0,\n",
    "    \"random_state\": 42,\n",
    "    \"test_size\" : 0.2,\n",
    "    \"droped_column\" : ['ID','IPv','Drate','Telnet','SMTP','ARP','cwr_flag_number','ece_flag_number','fin_flag_number','SSH','psh_flag_number','rst_flag_number'],\n",
    "    \"author\": \"Son Nguyen\"\n",
    "}\n",
    "\n",
    "def xgboost_objective(trial):\n",
    "    with mlflow.start_run(nested=True) as run:\n",
    "        params = {\n",
    "            \"tree_method\" : \"hist\",\n",
    "            \"device\" : \"cuda\",\n",
    "            \"objective\": \"reg:squarederror\",\n",
    "            \"n_estimators\": 1000,\n",
    "            \"verbosity\": 0,\n",
    "            \"eval_metric\" : [\"rmse\", \"mae\", \"mape\", \"logloss\",\"error\",\"auc\"],\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 10, 50),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.3, 0.8),\n",
    "            \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1,15),\n",
    "        }\n",
    "        model = XGBClassifier(**params)\n",
    "        mlflow.xgboost.autolog()\n",
    "        model.fit(X_train, y_train, verbose=False)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        precision = precision_score(y_test, y_pred, average='weighted')\n",
    "        recall = recall_score(y_test, y_pred, average='weighted')\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "\n",
    "        metrics_file = \"model_summary.json\"\n",
    "        metrics = {\n",
    "            \"parameter\" : {**params},\n",
    "            \"metrics\" : {\n",
    "                \"f1\" : f1,\n",
    "                \"precision\" : precision,\n",
    "                \"accuracy\" : accuracy,\n",
    "                \"recall\" : recall\n",
    "            },\n",
    "            \"droped_column\" : [tags[\"droped_column\"]]\n",
    "            \n",
    "        }\n",
    "        \n",
    "        with open(metrics_file, \"w\") as f:\n",
    "            json.dump(metrics, f, indent=4)\n",
    "        mlflow.log_artifact(metrics_file)\n",
    "        os.remove(metrics_file)\n",
    "\n",
    "        pickle_file = \"model.pkl\"\n",
    "        with open(pickle_file, \"wb\") as f:\n",
    "            pickle.dump(model, f)\n",
    "\n",
    "        mlflow.log_artifact(f\"model/{pickle_file}\")\n",
    "        os.remove(pickle_file)\n",
    "    \n",
    "\n",
    "        trial.set_user_attr(\"run_id\", run.info.run_id)\n",
    "    return f1\n",
    "\n",
    "def champion_callback(study, frozen_trial):\n",
    "    winner = study.user_attrs.get(\"winner\", None)\n",
    "    if study.best_value and winner != study.best_value:\n",
    "        study.set_user_attr(\"winner\", study.best_value)\n",
    "        if winner:\n",
    "            improvement_percent = (abs(winner - study.best_value) / study.best_value) * 100\n",
    "            print(\n",
    "                f\"Trial {frozen_trial.number} achieved value: {frozen_trial.value} with \"\n",
    "                f\"{improvement_percent: .4f}% improvement\"\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Initial trial {frozen_trial.number} achieved value: {frozen_trial.value}\")\n",
    "\n",
    "data = random_fill.drop(columns=tags['droped_column'])\n",
    "data_sample = data.sample(frac=tags['dataset_frac'])\n",
    "X = data_sample.drop(columns=['Label'])\n",
    "y = data_sample['Label']\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = tags['test_size'], random_state = tags['random_state'])\n",
    "\n",
    "mlflow.set_experiment(\"xgboost\")\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "with mlflow.start_run(nested=True) as run:\n",
    "\n",
    "    # mlflow.xgboost.autolog() can not put auto log here\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(xgboost_objective, n_trials=100, timeout=14400, callbacks=[champion_callback], show_progress_bar=True)\n",
    "    \n",
    "    best_trial = study.best_trial\n",
    "    best_run_id = best_trial.user_attrs['run_id']\n",
    "    best_value = study.best_value\n",
    "\n",
    "    model_name = \"XGBoost-Classifier\"\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    latest_ = client.get_latest_versions(model_name, stages=None)[0]\n",
    "\n",
    "\n",
    "    if latest_:\n",
    "        previous_f1_score = client.get_metric_history(latest_.run_id, \"f1_score\")[-1].value\n",
    "        if previous_f1_score >= best_value:\n",
    "            print(f\"Last model is better. Current values {best_value}, latest values {previous_f1_score}\")\n",
    "        else:\n",
    "\n",
    "            model_uri = f\"runs:/{best_run_id}/model\"\n",
    "            best_model = mlflow.register_model(model_uri, model_name)\n",
    "            best_param = client.get_run(best_run_id).data.params\n",
    "\n",
    "            client.update_registered_model(\n",
    "                name=model_name,\n",
    "                description=\"Best moldel\",\n",
    "            )\n",
    "\n",
    "            for key, value in best_param.items():\n",
    "                client.set_model_version_tag(\n",
    "                    name=model_name,\n",
    "                    version=best_model.version,\n",
    "                    key=key,\n",
    "                    value=value\n",
    "                )\n",
    "\n",
    "            client.set_model_version_tag(\n",
    "                name=model_name,\n",
    "                version=best_model.version,\n",
    "                key=\"values\",\n",
    "                value=best_value\n",
    "            )\n",
    "\n",
    "            for key, value in tags.items():\n",
    "                mlflow.set_tag(key,value)\n",
    "            mlflow.set_tag(\"job\", \"xgboost using optuna to search parameter\")\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
