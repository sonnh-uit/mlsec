{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Install dependencies\n",
    "# # !pip3 uninstall numpy\n",
    "# !pip3 install --upgrade numpy==2.0.0\n",
    "# !pip3 install pandas\n",
    "# !pip3 install scikit-learn mlflow seaborn shap\n",
    "# !pip3 install bayesian-optimization\n",
    "# !pip3 install xgboost==2.1.2\n",
    "# !pip3 install optuna\n",
    "# !pip3 install optuna-integration[mlflow]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "from mlflow.models import infer_signature, make_metric\n",
    "from optuna.integration.mlflow import MLflowCallback\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import optuna, pickle\n",
    "import os, json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset\n",
    "Because test dataset not have label, we must split train dataset to 2 parts. One for train and one for validate. We just do this on the first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset\n",
    "# df = pd.read_csv('data/data.csv')\n",
    "# train_test_data, validate_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "# train_test_data.to_csv('data/train_.csv', index=False, header=True)\n",
    "# validate_data.to_csv('data/validate.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we check some information of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                      0\n",
       "flow_duration           0\n",
       "Header_Length      155801\n",
       "Protocol type      155810\n",
       "Duration           156043\n",
       "Rate               156180\n",
       "Srate              156075\n",
       "Drate              156049\n",
       "fin_flag_number         0\n",
       "syn_flag_number         0\n",
       "rst_flag_number    156030\n",
       "psh_flag_number    156006\n",
       "ack_flag_number         0\n",
       "ece_flag_number    155889\n",
       "cwr_flag_number    156119\n",
       "ack_count          156078\n",
       "syn_count          156278\n",
       "fin_count               0\n",
       "urg_count               0\n",
       "rst_count               0\n",
       "HTTP               155993\n",
       "HTTPS              156399\n",
       "DNS                     0\n",
       "Telnet             156044\n",
       "SMTP               155832\n",
       "SSH                156261\n",
       "IRC                     0\n",
       "TCP                156010\n",
       "UDP                     0\n",
       "DHCP                    0\n",
       "ARP                156189\n",
       "ICMP               155988\n",
       "IPv                     0\n",
       "LLC                     0\n",
       "Tot sum            155800\n",
       "Min                156138\n",
       "Max                155961\n",
       "AVG                     0\n",
       "Std                156058\n",
       "Tot size           155938\n",
       "IAT                156215\n",
       "Number                  0\n",
       "Magnitue                0\n",
       "Radius             155906\n",
       "Covariance         156232\n",
       "Variance           156106\n",
       "Weight                  0\n",
       "Label                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check dataset\n",
    "df = pd.read_csv('data/train_.csv')\n",
    "# df.head()\n",
    "# print(\"Dataset column\")\n",
    "# df.columns\n",
    "# print(\"Summary of dataset info\")\n",
    "# df.info()\n",
    "# print(\"view dimensions of dataset\")\n",
    "# df.shape\n",
    "\n",
    "# for col in df.columns:\n",
    "#   if df[col].dtype != 'object':  # Exclude non-numeric columns\n",
    "#     min_val = df[col].min()\n",
    "#     max_val = df[col].max()\n",
    "#     print(f\"Column: {col}\")\n",
    "#     print(f\"Minimum: {min_val}\")\n",
    "#     print(f\"Maximum: {max_val}\")\n",
    "#     print()\n",
    "\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see some cell have null value, we can not drop which rows have null cell because it to much. So we just fill all null value = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nulls_with_random(df):\n",
    "    def fill_column(col):\n",
    "        if col.isnull().any():  # Only process columns with NaN values\n",
    "            col_min = col.min()\n",
    "            col_max = col.max()\n",
    "            # Ensure min and max are valid for randomization\n",
    "            if np.isnan(col_min) or np.isnan(col_max):\n",
    "                return col  # Skip if column only contains NaNs\n",
    "            col = col.apply(lambda x: np.random.uniform(col_min, col_max) if pd.isnull(x) else x)\n",
    "        return col\n",
    "\n",
    "    return df.apply(fill_column, axis=0)\n",
    "\n",
    "# Fill NaN values with random values\n",
    "\n",
    "random_fill = fill_nulls_with_random(df)\n",
    "\n",
    "# data_n_null.isnull().sum()\n",
    "# data_n_null.head()\n",
    "# data_n_null.duplicated().sum()\n",
    "# data_n_null['Label'].unique().tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For tracking during training, we using MLflow. The software defined by container in mlflow folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set mlflow as tracking server\n",
    "ML_TRACKING_URL = \"http://localhost:5000\"\n",
    "mlflow.set_tracking_uri(ML_TRACKING_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model\n",
    "We train with some model with these steps\n",
    "- We training with small part of dataset (0.2 or 0.3): dataset_frac\n",
    "- We log artifacts, we see some column less contribute in  Feature Importance Score, so we delete it\n",
    "- We train with full dataset, verify droped column is correct and need modify or not\n",
    "- We use RandomizedSearchCV to search parameter\n",
    "- We save best parameter to mlflow. With mlflow.sklearn.autolog, model and its metrics was save to model registry. We just download it and use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tags = {\n",
    "#     \"dataset_frac\": 1.0,\n",
    "#     \"test_size\" : 0.2,\n",
    "#     \"droped_column\" : ['ID','IPv','DNS','IRC','DHCP','ARP','SMTP','cwr_flag_number','ece_flag_number','Telnet','Drate','psh_flag_number','rst_flag_number','LLC', 'TCP','SSH','HTTPS','ack_flag_number','Std','Tot size', 'ack_count'],\n",
    "#     \"author\": \"Son Nguyen\"\n",
    "# }\n",
    "\n",
    "# def dct_objective(trial):\n",
    "#     with mlflow.start_run(nested=True) as run:\n",
    "#         # params = {\n",
    "#         #     \"max_features\": trial.suggest_int(\"max_features\", 30, 100, step=2),\n",
    "#         #     \"criterion\": trial.suggest_categorical(\"criterion\", [\"gini\"]),\n",
    "#         #     \"max_depth\": trial.suggest_int(\"max_depth\", 1000, 1500, step=50),\n",
    "#         #     \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 18, 30, step=2),\n",
    "#         #     \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 10, 16, step = 1),\n",
    "#         #     \"random_state\" : 42\n",
    "#         # }\n",
    "#         params = {\n",
    "#             \"max_features\": trial.suggest_int(\"max_features\", 50, 70, step=1),\n",
    "#             \"criterion\": trial.suggest_categorical(\"criterion\", [\"entropy\"]),\n",
    "#             \"splitter\": trial.suggest_categorical(\"splitter\", [\"best\"]),\n",
    "#             \"max_depth\": trial.suggest_int(\"max_depth\", 1100, 1800, step=50),\n",
    "#             \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 17, 24, step=1),\n",
    "#             \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 10, 16, step=1),\n",
    "#             \"min_impurity_decrease\": trial.suggest_float(\"min_impurity_decrease\", 0.0, 0.001, step=0.0001),\n",
    "#             \"ccp_alpha\": trial.suggest_float(\"ccp_alpha\", 0.0, 0.001, step=0.0001),\n",
    "#             \"class_weight\": trial.suggest_categorical(\"class_weight\", [None, \"balanced\"]),\n",
    "#             \"max_leaf_nodes\": trial.suggest_int(\"max_leaf_nodes\", 150, 250, step=5),\n",
    "#             \"random_state\": 42\n",
    "#         }\n",
    "#         model = DecisionTreeClassifier(**params)\n",
    "\n",
    "#         mlflow.sklearn.autolog()\n",
    "#         model.fit(X_train, y_train)\n",
    "#         y_pred = model.predict(X_test)\n",
    "#         accuracy = accuracy_score(y_test, y_pred)\n",
    "#         f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "#         precision = precision_score(y_test, y_pred, average='weighted')\n",
    "#         recall = recall_score(y_test, y_pred, average='weighted')\n",
    "#         mlflow.log_metric(\"accuracy\", accuracy)\n",
    "#         mlflow.log_metric(\"f1_score\", f1)\n",
    "#         mlflow.log_metric(\"precision\", precision)\n",
    "#         mlflow.log_metric(\"recall\", recall)\n",
    "\n",
    "\n",
    "#         feature_scores = pd.Series(model.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "#         plt.figure(figsize=(20, 20))\n",
    "#         sns.barplot(x=feature_scores, y=feature_scores.index)\n",
    "#         plt.xlabel('Feature Importance Score')\n",
    "#         plt.ylabel('Features')\n",
    "#         plt.title(\"Visualizing Important Features\")\n",
    "#         feature_importance_plot = \"feature_importance.png\"\n",
    "#         plt.savefig(feature_importance_plot, bbox_inches='tight')\n",
    "#         mlflow.log_artifact(feature_importance_plot)\n",
    "#         os.remove(feature_importance_plot)\n",
    "\n",
    "        \n",
    "#         metrics_file = \"model_summary.json\"\n",
    "#         metrics = {\n",
    "#             \"parameter\" : {**params},\n",
    "#             \"metrics\" : {\n",
    "#                 \"f1\" : f1,\n",
    "#                 \"precision\" : precision,\n",
    "#                 \"accuracy\" : accuracy,\n",
    "#                 \"recall\" : recall\n",
    "#             },\n",
    "#             \"droped_column\" : [tags[\"droped_column\"]]\n",
    "            \n",
    "#         }\n",
    "        \n",
    "#         with open(metrics_file, \"w\") as f:\n",
    "#             json.dump(metrics, f, indent=4)\n",
    "\n",
    "#         mlflow.log_artifact(metrics_file)\n",
    "#         os.remove(metrics_file)\n",
    "\n",
    "#         trial.set_user_attr(\"run_id\", run.info.run_id)\n",
    "#     return f1\n",
    "\n",
    "\n",
    "# def dct_callback(study, frozen_trial):\n",
    "#     winner = study.user_attrs.get(\"winner\", None)\n",
    "#     if study.best_value and winner != study.best_value:\n",
    "#         study.set_user_attr(\"winner\", study.best_value)\n",
    "#         if winner:\n",
    "#             improvement_percent = (abs(winner - study.best_value) / study.best_value) * 100\n",
    "#             print(\n",
    "#                 f\"Trial {frozen_trial.number} achieved value: {frozen_trial.value} with \"\n",
    "#                 f\"{improvement_percent: .4f}% improvement\"\n",
    "#             )\n",
    "#         else:\n",
    "#             print(f\"Initial trial {frozen_trial.number} achieved value: {frozen_trial.value}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# data = random_fill.drop(columns=tags['droped_column'])\n",
    "# data_sample = data.sample(frac=tags['dataset_frac'])\n",
    "# X = data_sample.drop(columns=['Label'])\n",
    "# scaler = StandardScaler()\n",
    "# X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# y = data_sample['Label']\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = tags['test_size'], random_state = 42)\n",
    "\n",
    "\n",
    "# mlflow.set_experiment(\"decision_tree\")\n",
    "# optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "\n",
    "\n",
    "\n",
    "# with mlflow.start_run(nested=True) as run:\n",
    "\n",
    "#     # mlflow.xgboost.autolog() can not put auto log here\n",
    "#     study = optuna.create_study(direction='maximize')\n",
    "#     study.optimize(dct_objective, n_trials=100, timeout=14400, callbacks=[dct_callback], show_progress_bar=True)\n",
    "#     # study.optimize(dct_objective, n_trials=100, timeout=100, callbacks=[dct_callback], show_progress_bar=True)\n",
    "    \n",
    "#     best_trial = study.best_trial\n",
    "#     best_run_id = best_trial.user_attrs['run_id']\n",
    "#     # best_param = study.best_params\n",
    "#     best_value = study.best_value\n",
    "\n",
    "#     model_name = \"Decision Tree\"\n",
    "#     client = mlflow.tracking.MlflowClient()\n",
    "#     latest_ = client.get_latest_versions(model_name, stages=None)[0]\n",
    "\n",
    "\n",
    "#     if latest_:\n",
    "#         previous_f1_score = client.get_metric_history(latest_.run_id, \"f1_score\")[-1].value\n",
    "#         if previous_f1_score >= best_value:\n",
    "#             print(f\"Last model is better. Current values {best_value}, latest values {previous_f1_score}\")\n",
    "#         else:\n",
    "#             model_uri = f\"runs:/{best_run_id}/model\"\n",
    "#             best_model = mlflow.register_model(model_uri, model_name)\n",
    "#             best_param = client.get_run(best_run_id).data.params\n",
    "\n",
    "#             client.update_registered_model(\n",
    "#                 name=model_name,\n",
    "#                 description=\"Best moldel\",\n",
    "#             )\n",
    "\n",
    "#             for key, value in best_param.items():\n",
    "#                 client.set_model_version_tag(\n",
    "#                     name=model_name,\n",
    "#                     version=best_model.version,\n",
    "#                     key=key,\n",
    "#                     value=value\n",
    "#                 )\n",
    "\n",
    "#             client.set_model_version_tag(\n",
    "#                 name=model_name,\n",
    "#                 version=best_model.version,\n",
    "#                 key=\"values\",\n",
    "#                 value=best_value\n",
    "#             )\n",
    "\n",
    "#             for key, value in tags.items():\n",
    "#                 mlflow.set_tag(key,value)\n",
    "#             mlflow.set_tag(\"job\", \"Decision Tree using optuna to search parameter\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tags = {\n",
    "#     \"dataset_frac\": 1.0,\n",
    "#     \"test_size\" : 0.2,\n",
    "#     # \"droped_column\" : ['ID'],\n",
    "#     \"droped_column\" : ['ID','IPv', 'Telnet', 'SMTP', 'IRC', 'SSH', 'DHCP', 'ARP', 'DNS', 'Drate', 'ece_flag_number', 'cwr_flag_number', 'Duration', 'HTTP','HTTPS'],\n",
    "#     \"author\": \"Son Nguyen\"\n",
    "# }\n",
    "\n",
    "# def rdf_objective(trial):\n",
    "#     with mlflow.start_run(nested=True) as run:\n",
    "#         params = {\n",
    "#             \"n_estimators\": trial.suggest_int(\"n_estimators\", 500, 1500, step=50),\n",
    "#             \"max_features\": trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\"]),\n",
    "#             \"criterion\": trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\",\"entropy\"]),\n",
    "#             \"max_depth\": trial.suggest_int(\"max_depth\",50, 100, step=10),\n",
    "#             \"max_leaf_nodes\": trial.suggest_int(\"max_leaf_nodes\", 100, 500, step=50),\n",
    "#             \"min_samples_leaf\": trial.suggest_float(\"min_samples_leaf\", 0.01, 0.1, step=0.01),\n",
    "#             \"min_weight_fraction_leaf\": trial.suggest_float(\"min_weight_fraction_leaf\", 0.01, 0.05, step=0.005),\n",
    "#             \"min_impurity_decrease\": trial.suggest_float(\"min_impurity_decrease\", 0.01, 0.05, step=0.001),\n",
    "#             \"ccp_alpha\": trial.suggest_float(\"ccp_alpha\", 0.01, 0.05, step=0.001),\n",
    "#             \"max_samples\": trial.suggest_float(\"max_samples\", 0.5, 1.0, step=0.01),\n",
    "#             \"class_weight\": trial.suggest_categorical(\"class_weight\", [None, \"balanced\", None, None]),\n",
    "#             \"random_state\": 42,\n",
    "#         }\n",
    "#         # params = {\n",
    "#         #     \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200, step=10),\n",
    "#         #     \"max_features\": trial.suggest_categorical(\"max_features\", [None, \"sqrt\", \"log2\"]),\n",
    "#         #     \"criterion\": trial.suggest_categorical(\"criterion\", [\"log_loss\", \"gini\", \"entropy\"]),\n",
    "#         #     \"max_depth\": trial.suggest_int(\"max_depth\", 500, 2000, step=50),\n",
    "#         #     \"max_leaf_nodes\": trial.suggest_int(\"max_leaf_nodes\", 100, 2000, step=50),\n",
    "#         #     \"min_samples_leaf\": trial.suggest_float(\"min_samples_leaf\", 0.01, 1.0, step=0.01),\n",
    "#         #     \"min_weight_fraction_leaf\": trial.suggest_float(\"min_weight_fraction_leaf\", 0.01, 0.5, step=0.01),\n",
    "#         #     \"min_impurity_decrease\": trial.suggest_float(\"min_impurity_decrease\", 0.01, 1.0, step=0.01),\n",
    "#         #     \"ccp_alpha\": trial.suggest_float(\"ccp_alpha\", 0.01, 1.0, step=0.01),\n",
    "#         #     \"max_samples\" : None,\n",
    "#         #     \"random_state\": 42\n",
    "#         # }\n",
    "#         model = RandomForestClassifier(**params)\n",
    "\n",
    "#         mlflow.sklearn.autolog()\n",
    "#         model.fit(X_train, y_train)\n",
    "#         y_pred = model.predict(X_test)\n",
    "#         accuracy = accuracy_score(y_test, y_pred)\n",
    "#         f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "#         precision = precision_score(y_test, y_pred, average='weighted')\n",
    "#         recall = recall_score(y_test, y_pred, average='weighted')\n",
    "#         mlflow.log_metric(\"accuracy\", accuracy)\n",
    "#         mlflow.log_metric(\"f1_score\", f1)\n",
    "#         mlflow.log_metric(\"precision\", precision)\n",
    "#         mlflow.log_metric(\"recall\", recall)\n",
    "\n",
    "\n",
    "#         feature_scores = pd.Series(model.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "#         plt.figure(figsize=(20, 20))\n",
    "#         sns.barplot(x=feature_scores, y=feature_scores.index)\n",
    "#         plt.xlabel('Feature Importance Score')\n",
    "#         plt.ylabel('Features')\n",
    "#         plt.title(\"Visualizing Important Features\")\n",
    "#         feature_importance_plot = \"feature_importance.png\"\n",
    "#         plt.savefig(feature_importance_plot, bbox_inches='tight')\n",
    "#         mlflow.log_artifact(feature_importance_plot)\n",
    "#         os.remove(feature_importance_plot)\n",
    "\n",
    "        \n",
    "#         metrics_file = \"model_summary.json\"\n",
    "#         metrics = {\n",
    "#             \"parameter\" : {**params},\n",
    "#             \"metrics\" : {\n",
    "#                 \"f1\" : f1,\n",
    "#                 \"precision\" : precision,\n",
    "#                 \"accuracy\" : accuracy,\n",
    "#                 \"recall\" : recall\n",
    "#             },\n",
    "#             \"droped_column\" : [tags[\"droped_column\"]]\n",
    "            \n",
    "#         }\n",
    "        \n",
    "#         with open(metrics_file, \"w\") as f:\n",
    "#             json.dump(metrics, f, indent=4)\n",
    "\n",
    "#         mlflow.log_artifact(metrics_file)\n",
    "#         os.remove(metrics_file)\n",
    "\n",
    "#         trial.set_user_attr(\"run_id\", run.info.run_id)\n",
    "#     return f1\n",
    "\n",
    "\n",
    "# def rdf_callback(study, frozen_trial):\n",
    "#     winner = study.user_attrs.get(\"winner\", None)\n",
    "#     if study.best_value and winner != study.best_value:\n",
    "#         study.set_user_attr(\"winner\", study.best_value)\n",
    "#         if winner:\n",
    "#             improvement_percent = (abs(winner - study.best_value) / study.best_value) * 100\n",
    "#             print(\n",
    "#                 f\"Trial {frozen_trial.number} achieved value: {frozen_trial.value} with \"\n",
    "#                 f\"{improvement_percent: .4f}% improvement\"\n",
    "#             )\n",
    "#         else:\n",
    "#             print(f\"Initial trial {frozen_trial.number} achieved value: {frozen_trial.value}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# data = random_fill.drop(columns=tags['droped_column'])\n",
    "# data_sample = data.sample(frac=tags['dataset_frac'])\n",
    "# X = data_sample.drop(columns=['Label'])\n",
    "# scaler = StandardScaler()\n",
    "# X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# y = data_sample['Label']\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = tags['test_size'], random_state = 42)\n",
    "\n",
    "\n",
    "# mlflow.set_experiment(\"random-forest\")\n",
    "# optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "\n",
    "\n",
    "\n",
    "# with mlflow.start_run(nested=True) as run:\n",
    "\n",
    "#     # mlflow.xgboost.autolog() can not put auto log here\n",
    "#     study = optuna.create_study(direction='maximize')\n",
    "#     study.optimize(rdf_objective, n_trials=100, timeout=14400, callbacks=[rdf_callback], show_progress_bar=True)\n",
    "#     # study.optimize(dct_objective, n_trials=100, timeout=100, callbacks=[dct_callback], show_progress_bar=True)\n",
    "    \n",
    "#     best_trial = study.best_trial\n",
    "#     best_run_id = best_trial.user_attrs['run_id']\n",
    "#     # best_param = study.best_params\n",
    "#     best_value = study.best_value\n",
    "\n",
    "#     model_name = \"RandomForestClassifier\"\n",
    "#     client = mlflow.tracking.MlflowClient()\n",
    "#     latest_ = client.get_latest_versions(model_name, stages=None)[0]\n",
    "\n",
    "\n",
    "#     if latest_:\n",
    "#         previous_f1_score = client.get_metric_history(latest_.run_id, \"f1_score\")[-1].value\n",
    "#         if previous_f1_score >= best_value:\n",
    "#             print(f\"Last model is better. Current values {best_value}, latest values {previous_f1_score}\")\n",
    "#         else:\n",
    "#             model_uri = f\"runs:/{best_run_id}/model\"\n",
    "#             best_model = mlflow.register_model(model_uri, model_name)\n",
    "#             best_param = client.get_run(best_run_id).data.params\n",
    "\n",
    "#             client.update_registered_model(\n",
    "#                 name=model_name,\n",
    "#                 description=\"Best moldel\",\n",
    "#             )\n",
    "\n",
    "#             for key, value in best_param.items():\n",
    "#                 client.set_model_version_tag(\n",
    "#                     name=model_name,\n",
    "#                     version=best_model.version,\n",
    "#                     key=key,\n",
    "#                     value=value\n",
    "#                 )\n",
    "\n",
    "#             client.set_model_version_tag(\n",
    "#                 name=model_name,\n",
    "#                 version=best_model.version,\n",
    "#                 key=\"values\",\n",
    "#                 value=best_value\n",
    "#             )\n",
    "\n",
    "#             for key, value in tags.items():\n",
    "#                 mlflow.set_tag(key,value)\n",
    "#             mlflow.set_tag(\"job\", \"RandomForest Classifier using optuna to search parameter\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cedd0db720b4ea4a5212746c761db47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/12 13:35:08 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\project\\mlsec\\final\\project\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [13:35:08] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run bouncy-finch-672 at: http://localhost:5000/#/experiments/2/runs/a853316fa85747958a00f5bac0394ced\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/2\n",
      "Initial trial 0 achieved value: 0.9383339764726146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/12 14:12:54 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\project\\mlsec\\final\\project\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:12:54] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run enthused-robin-930 at: http://localhost:5000/#/experiments/2/runs/bf74d1883acd4ff1961efe4876a24460\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/12 14:33:10 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\project\\mlsec\\final\\project\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:33:10] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run polite-loon-908 at: http://localhost:5000/#/experiments/2/runs/da19c8417bda4da4a3548529c7496c97\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/2\n",
      "Trial 2 achieved value: 0.9384571676833849 with  0.0131% improvement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/12 14:47:23 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\project\\mlsec\\final\\project\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:47:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run gifted-hare-849 at: http://localhost:5000/#/experiments/2/runs/93a409cb6e224ee7a6e8bfb5d8a9d536\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/12 14:56:16 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\project\\mlsec\\final\\project\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:56:16] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run vaunted-lynx-784 at: http://localhost:5000/#/experiments/2/runs/0db0709d2a1342db92a6b5b752c6c1cd\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/12 15:30:17 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\project\\mlsec\\final\\project\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [15:30:17] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run bright-crab-973 at: http://localhost:5000/#/experiments/2/runs/e349b3d0ce844168982e1c454f4b121a\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/12 15:58:39 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\project\\mlsec\\final\\project\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [15:58:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run nosy-dog-774 at: http://localhost:5000/#/experiments/2/runs/a2e23a5d67ae45f2a700095109866e59\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/12 16:09:53 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\project\\mlsec\\final\\project\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:09:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run persistent-stoat-631 at: http://localhost:5000/#/experiments/2/runs/5438ef74e66f4e85ab30226b87d5674a\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/12 16:16:56 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\project\\mlsec\\final\\project\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:16:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run lyrical-moth-675 at: http://localhost:5000/#/experiments/2/runs/a6c7f39b92794fbdb88d8c51df98b70b\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/12 16:27:59 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\project\\mlsec\\final\\project\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:27:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run bold-dog-832 at: http://localhost:5000/#/experiments/2/runs/120179d5cdef435298bd4bd957d9a33c\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/12 16:40:23 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\project\\mlsec\\final\\project\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:40:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run tasteful-bass-311 at: http://localhost:5000/#/experiments/2/runs/51ad6628ed544a31ab74543a51c9f948\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/2\n",
      "Trial 10 achieved value: 0.9387632372312676 with  0.0326% improvement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/12 16:52:45 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\project\\mlsec\\final\\project\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:52:45] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run nimble-whale-291 at: http://localhost:5000/#/experiments/2/runs/7beb7ed980964c9b9be092d1517f33af\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/12 17:03:40 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\project\\mlsec\\final\\project\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:03:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run capricious-hound-514 at: http://localhost:5000/#/experiments/2/runs/d94173fc48b74379afdf5c935795f5a4\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/12 17:17:44 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\project\\mlsec\\final\\project\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:17:44] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run gregarious-snipe-221 at: http://localhost:5000/#/experiments/2/runs/5fcccac25bd14701bdb7b0b6d634af20\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/12 17:32:13 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\project\\mlsec\\final\\project\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:32:13] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run spiffy-stag-516 at: http://localhost:5000/#/experiments/2/runs/989dd43c9cbd4184b80434a9beff58e1\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/2\n",
      "Last model is better. Current values 0.9387632372312676, latest values 0.9391637958468314\n",
      "ðŸƒ View run vaunted-pig-847 at: http://localhost:5000/#/experiments/2/runs/1c19085c59804ee4b7119b5855d6de9e\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SonNH\\AppData\\Local\\Temp\\ipykernel_21460\\1426120245.py:94: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  latest_ = client.get_latest_versions(model_name, stages=None)[0]\n"
     ]
    }
   ],
   "source": [
    "tags = {\n",
    "    \"dataset_frac\": 1.0,\n",
    "    \"random_state\": 42,\n",
    "    \"test_size\" : 0.2,\n",
    "    \"droped_column\" : ['ID','IPv','Drate','Telnet','SMTP','ARP','cwr_flag_number','ece_flag_number','fin_flag_number','SSH','psh_flag_number','rst_flag_number','DNS', 'LLC','syn_flag_number'],\n",
    "    \"author\": \"Son Nguyen\"\n",
    "}\n",
    "\n",
    "def xgboost_objective(trial):\n",
    "    with mlflow.start_run(nested=True) as run:\n",
    "        params = {\n",
    "            \"tree_method\" : \"hist\",\n",
    "            \"device\" : \"cuda\",\n",
    "            \"objective\": \"reg:squarederror\",\n",
    "            \"n_estimators\": 1000,\n",
    "            \"verbosity\": 0,\n",
    "            \"eval_metric\" : [\"rmse\", \"mae\", \"mape\", \"logloss\",\"error\",\"auc\"],\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 10, 50),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.3, 0.8),\n",
    "            \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1,15),\n",
    "        }\n",
    "        model = XGBClassifier(**params)\n",
    "        mlflow.xgboost.autolog()\n",
    "        model.fit(X_train, y_train, verbose=False)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        precision = precision_score(y_test, y_pred, average='weighted')\n",
    "        recall = recall_score(y_test, y_pred, average='weighted')\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "\n",
    "        metrics_file = \"model_summary.json\"\n",
    "        metrics = {\n",
    "            \"parameter\" : {**params},\n",
    "            \"metrics\" : {\n",
    "                \"f1\" : f1,\n",
    "                \"precision\" : precision,\n",
    "                \"accuracy\" : accuracy,\n",
    "                \"recall\" : recall\n",
    "            },\n",
    "            \"droped_column\" : [tags[\"droped_column\"]]\n",
    "            \n",
    "        }\n",
    "        \n",
    "        with open(metrics_file, \"w\") as f:\n",
    "            json.dump(metrics, f, indent=4)\n",
    "\n",
    "        mlflow.log_artifact(metrics_file)\n",
    "        os.remove(metrics_file)\n",
    "\n",
    "        trial.set_user_attr(\"run_id\", run.info.run_id)\n",
    "    return f1\n",
    "\n",
    "def champion_callback(study, frozen_trial):\n",
    "    winner = study.user_attrs.get(\"winner\", None)\n",
    "    if study.best_value and winner != study.best_value:\n",
    "        study.set_user_attr(\"winner\", study.best_value)\n",
    "        if winner:\n",
    "            improvement_percent = (abs(winner - study.best_value) / study.best_value) * 100\n",
    "            print(\n",
    "                f\"Trial {frozen_trial.number} achieved value: {frozen_trial.value} with \"\n",
    "                f\"{improvement_percent: .4f}% improvement\"\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Initial trial {frozen_trial.number} achieved value: {frozen_trial.value}\")\n",
    "\n",
    "data = random_fill.drop(columns=tags['droped_column'])\n",
    "data_sample = data.sample(frac=tags['dataset_frac'])\n",
    "X = data_sample.drop(columns=['Label'])\n",
    "y = data_sample['Label']\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = tags['test_size'], random_state = tags['random_state'])\n",
    "\n",
    "mlflow.set_experiment(\"xgboost\")\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "with mlflow.start_run(nested=True) as run:\n",
    "\n",
    "    # mlflow.xgboost.autolog() can not put auto log here\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(xgboost_objective, n_trials=100, timeout=14400, callbacks=[champion_callback], show_progress_bar=True)\n",
    "    \n",
    "    best_trial = study.best_trial\n",
    "    best_run_id = best_trial.user_attrs['run_id']\n",
    "    best_value = study.best_value\n",
    "\n",
    "    model_name = \"XGBoost-Classifier\"\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    latest_ = client.get_latest_versions(model_name, stages=None)[0]\n",
    "\n",
    "\n",
    "    if latest_:\n",
    "        previous_f1_score = client.get_metric_history(latest_.run_id, \"f1_score\")[-1].value\n",
    "        if previous_f1_score >= best_value:\n",
    "            print(f\"Last model is better. Current values {best_value}, latest values {previous_f1_score}\")\n",
    "        else:\n",
    "            model_uri = f\"runs:/{best_run_id}/model\"\n",
    "            best_model = mlflow.register_model(model_uri, model_name)\n",
    "            best_param = client.get_run(best_run_id).data.params\n",
    "            client.update_registered_model(\n",
    "                name=model_name,\n",
    "                description=\"Best moldel\",\n",
    "            )\n",
    "\n",
    "            for key, value in best_param.items():\n",
    "                client.set_model_version_tag(\n",
    "                    name=model_name,\n",
    "                    version=best_model.version,\n",
    "                    key=key,\n",
    "                    value=value\n",
    "                )\n",
    "\n",
    "            client.set_model_version_tag(\n",
    "                name=model_name,\n",
    "                version=best_model.version,\n",
    "                key=\"values\",\n",
    "                value=best_value\n",
    "            )\n",
    "\n",
    "            for key, value in tags.items():\n",
    "                mlflow.set_tag(key,value)\n",
    "            mlflow.set_tag(\"job\", \"xgboost using optuna to search parameter\")\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
